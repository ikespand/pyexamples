{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using ESN to build an e2e prediction system with more features (WIP)\n",
    "Continuation of `1_esn_le2e.ipynb` notebook with an aim to enhance accuracy by fusing more features like some common TAs. More of a exploration than the final results.|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Obtaining data\n",
    "Here, we get the data from Yahoo Finance API (yfinance package) which has some limitation for bulk and daily usage. So restricting the notebook to examination purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from easyesn import PredictionESN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_name = \"MSFT\"\n",
    "start_date=\"2021-01-01\"\n",
    "end_date=\"2025-03-28\"\n",
    "interval=\"1d\"\n",
    "n_steps = 7\n",
    "train_test_split = 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the instance for the given ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tikr = yf.Ticker(stock_name)\n",
    "tikr_history = tikr.history(start=start_date, end=end_date, interval=\"1d\")\n",
    "#tikr_history = tikr.history(period=\"1mo\", interval=\"5m\")\n",
    "#tikr_history = tikr.history(period=\"max\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can run sentiment analysis if we want on the current news."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(tikr.news)\n",
    "#print(tikr.info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of df\", tikr_history.shape)\n",
    "tikr_history.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tikr_history.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's focus on limited columns\n",
    "We will consider only 4 variables (Open, High, Low, Close), therefore dropping reamining columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tikr_history = tikr_history.drop([\"Dividends\", \"Stock Splits\"], axis=1)\n",
    "tikr_history.reset_index(inplace=True)\n",
    "tikr_history.head(5)\n",
    "df = tikr_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_ta as ta\n",
    "# Add RSI\n",
    "df['RSI_14'] = ta.rsi(df['Close'], length=14)\n",
    "\n",
    "# Add MACD (default values: fast=12, slow=26, signal=9)\n",
    "macd = ta.macd(df['Close'])\n",
    "df['MACD'] = macd['MACD_12_26_9']\n",
    "df['MACD_Signal'] = macd['MACDs_12_26_9']\n",
    "\n",
    "# Add Bollinger Bands\n",
    "bollinger = ta.bbands(df['Close'], length=20, std=2)\n",
    "df['BB_Upper'] = bollinger['BBU_20_2.0']\n",
    "df['BB_Lower'] = bollinger['BBL_20_2.0']\n",
    "df['BB_Middle'] = bollinger['BBM_20_2.0']\n",
    "\n",
    "# Add EMA (Exponential Moving Average)\n",
    "df['EMA_10'] = ta.ema(df['Close'], length=10)\n",
    "df['EMA_50'] = ta.ema(df['Close'], length=50)\n",
    "\n",
    "# Add ATR (Average True Range)\n",
    "df['ATR_14'] = ta.atr(df['High'], df['Low'], df['Close'], length=14)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Building ESN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data prepartion\n",
    "- Separating the train and test data with an 80-20% split\n",
    "- Scaling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MpOqQmlY61Dv",
    "outputId": "894a1e9e-a2de-4b62-c52c-121e47b828e6"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "# Define features\n",
    "FEATURES = [\"Open\", \"High\", \"Low\", \"Close\", \"Volume\", \"RSI_14\"]\n",
    "\n",
    "# Train-Test Split\n",
    "train_size = int(len(df) * train_test_split)\n",
    "train_df = df.iloc[:train_size]\n",
    "test_df = df.iloc[train_size:]\n",
    "\n",
    "# Scaling\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "train_scaled = scaler.fit_transform(train_df[FEATURES])\n",
    "test_scaled = scaler.transform(test_df[FEATURES])\n",
    "\n",
    "# Prepare Data for ESN Training\n",
    "def create_sequences(data, n_steps):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - n_steps):\n",
    "        X.append(data[i:i + n_steps].flatten())  # Flatten past n_steps\n",
    "        y.append(data[i + n_steps, -1].flatten())  # Next day's Close price\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Define sequence length (lookback window)\n",
    "n_steps = 6  # Adjust based on model performance\n",
    "\n",
    "x_train, y_train = create_sequences(train_scaled, n_steps)\n",
    "x_test, y_test = create_sequences(test_scaled, n_steps)\n",
    "\n",
    "print(\"X_train shape:\", x_train.shape)  # Should be (samples, n_steps * features)\n",
    "print(\"y_train shape:\", y_train.shape)  # Should be (samples,)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe above, the shape of `x` and `y`. Let's double check: If, current x(t=0) has 3 values then its y(t=0) will be equal to the last element(s) in x(t=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train[0][0]-x_train[n_steps][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "esn = PredictionESN(\n",
    "    n_input = x_train.shape[1],\n",
    "    n_output = y_train.shape[1],\n",
    "    n_reservoir= 100,\n",
    "    spectralRadius=1,\n",
    "    leakingRate=1,\n",
    "    feedback=False,\n",
    "    randomSeed = 42\n",
    ")\n",
    "esn.fit(x_train, y_train, transientTime=\"Auto\", verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict values from test data trained using training data and reverse transform\n",
    "y_hat_scaled = esn.predict(x_test)\n",
    "# Following part just to perform inverse transform as it expect n_features columns\n",
    "y_hat_scaled_4 = np.repeat(y_hat_scaled, 6, axis=1)\n",
    "y_hat = scaler.inverse_transform(y_hat_scaled_4)[:,0]\n",
    "print(\"y_test.shape, y_hat.shape\", y_test.shape, y_hat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_orig = test_df[n_steps:].reset_index(drop=True)\n",
    "# Visualise the ask_price predictions\n",
    "plt.figure(figsize = (8, 2))\n",
    "plt.plot(y_test_orig['Open'], color = 'red', linestyle = \"--\", label = 'y_test')\n",
    "plt.plot(y_hat, color = 'green', label = 'y_hat')\n",
    "plt.title('y_hat vs y_test')\n",
    "plt.ylabel('Open')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zoom-in to the last 100 values to see differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_orig = test_df[n_steps:].reset_index(drop=True)\n",
    "# Visualise the ask_price predictions\n",
    "plt.figure(figsize = (12, 2))\n",
    "plt.plot(y_test_orig['Open'][-100:].to_list(), color = 'red', linestyle = \"--\", label = 'y_test')\n",
    "plt.plot(y_hat[-100:], color = 'green', label = 'y_hat_esn')\n",
    "plt.title('y_hat vs y_test')\n",
    "plt.ylabel('Open')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export the model for future use (ESN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill as pickle\n",
    "pickle.dump(esn, open(f\"stock_esn_model_{n_steps}.pkl\", \"wb\"))\n",
    "# Can be use afterwards: esn = pickle.load(open(\"stock_esn_model.pkl\", \"rb\"))\n",
    "\n",
    "# Also save the scaler\n",
    "pickle.dump(scaler, open(f\"scaler_esn_model_{n_steps}.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "END OF NOTEBOOK"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "yahoo_api",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
